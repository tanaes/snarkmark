
rule qc_copy_files:
    """
    Combines multiple input fastqs per sample into a temporary single fastq
    """
    input:
        forward = lambda wildcards: config["samples"][wildcards.sample]["forward"],
        reverse = lambda wildcards: config["samples"][wildcards.sample]["reverse"]
    output:
        forward = temp(raw_dir + "{sample}/combined_reads/{sample}.R1.fastq.gz"),
        reverse = temp(raw_dir + "{sample}/combined_reads/{sample}.R2.fastq.gz")
    threads:
        1
    benchmark:
        "benchmarks/qc/qc_copy_files.sample_{sample}.txt"
    log:
        raw_dir + "logs/qc_copy_files.sample_{sample}.log"
    shell:
        """
        cp {input.forward} {output.forward}
        cp {input.reverse} {output.reverse}
        """

rule raw_per_sample_fastqc: 
    """
    Makes fastqc reports for each individual input file.
    """
    input:
        forward = raw_dir + "{sample}/combined_reads/{sample}.R1.fastq.gz",
        reverse = raw_dir + "{sample}/combined_reads/{sample}.R2.fastq.gz"
    output:
        html = raw_dir + "{sample}/fastqc_per_sample/{sample}.R1_fastqc.html",
        zip = raw_dir + "{sample}/fastqc_per_sample/{sample}.R2_fastqc.zip"
    threads:
        4
    benchmark:
        "benchmarks/qc/raw_per_sample_fastqc.sample_{sample}.txt"
    params:
        out_dir = raw_dir + "{sample}/fastqc_per_sample"
    log:
        raw_dir + "logs/raw_per_sample_fastqc.sample_{sample}.log"
    conda:
        "../envs/env_qc.yaml"
    shell:
        """
        fastqc --threads {threads} --outdir {params.out_dir} {input.forward} {input.reverse} 2> {log} 1>&2
        """

rule raw_per_sample_multiqc:
    """
    Runs multiqc for combined input files.
    """
    input:
        expand(raw_dir + "{sample}/fastqc_per_sample/{sample}.R2_fastqc.zip", sample=config['samples']),
    output:
        raw_dir + "multiQC_per_sample/multiqc_data/multiqc_general_stats.txt"
    threads:
        4
    params:
        out_dir = raw_dir + "multiQC_per_sample"
    log:
        raw_dir + "logs/raw_per_sample_multiqc.log"
    conda:
        "../envs/env_qc.yaml"
    shell:
        """
        multiqc -f -o {params.out_dir} {raw_dir}/*/fastqc_per_sample 2> {log} 1>&2
        """

rule qc_atropos:
    """
    Does adapter trimming and read QC with Atropos
    """
    input:
        forward = raw_dir + "{sample}/combined_reads/{sample}.R1.fastq.gz",
        reverse = raw_dir + "{sample}/combined_reads/{sample}.R2.fastq.gz"
    output:
        forward = qc_dir + "{sample}/atropos_trimmed/{sample}.trimmed.R1.fastq.gz",
        reverse = qc_dir + "{sample}/atropos_trimmed/{sample}.trimmed.R2.fastq.gz"
    threads:
        4
    params:
        atropos = config['params']['atropos']
    log:
        qc_dir + "logs/qc_atropos.sample_{sample}.log"
    benchmark:
        "benchmarks/qc/qc_atropos.sample_{sample}.txt"
    conda:
        "../envs/env_qc.yaml"
    shell:
        """
        atropos --threads {threads} {params.atropos} --report-file {log} --report-formats txt -o {output.forward} -p {output.reverse} -pe1 {input.forward} -pe2 {input.reverse}
        """


rule qc_filter:
    """
    Performs host read filtering on paired end data using Bowtie and Samtools/
    BEDtools. Takes the four output files generated by Trimmomatic. 

    Also requires an indexed reference (path specified in config). 

    First, uses Bowtie output piped through Samtools to only retain read pairs
    that are never mapped (either concordantly or just singly) to the indexed
    reference genome. Fastqs from this are gzipped into matched forward and 
    reverse pairs. 

    Unpaired forward and reverse reads are simply run through Bowtie and
    non-mapping gzipped reads output.

    All piped output first written to localscratch to avoid tying up filesystem.
    """
    input:
        forward = qc_dir + "{sample}/atropos_trimmed/{sample}.trimmed.R1.fastq.gz",
        reverse = qc_dir + "{sample}/atropos_trimmed/{sample}.trimmed.R2.fastq.gz"
    output:
        touch(qc_dir + "{sample}/filtered.done")
    params:
        filter_db = os.path.join(config['params']['db_dir'],
                                 config['params']['filter_db']),
        temp_dir = lambda wildcards: os.path.join(config['tmp_dir_root'],
                                                 'tmp_%s' % wildcards.sample,
                                                 'qc_filter')
    threads:
        8
    log:
        bowtie = qc_dir + "logs/qc_filter.bowtie.sample_{sample}.log",
        other = qc_dir + "logs/qc_filter.other.sample_{sample}.log"
    benchmark:
        "benchmarks/qc/qc_filter.sample_{sample}.txt"
    conda:
        "../envs/env_qc.yaml"
    shell:
        """
        mkdir -p {params.temp_dir}

        bowtie2 -p {threads} -x {params.filter_db} --very-sensitive -1 {input.forward} -2 {input.reverse} 2> {log.bowtie}| \
        samtools view -f 12 -F 256 -b -o {params.temp_dir}/{wildcards.sample}.unsorted.bam 2> {log.other} 

        samtools sort -T {params.temp_dir}/{wildcards.sample} -@ {threads} -n \
        -o {params.temp_dir}/{wildcards.sample}.bam {params.temp_dir}/{wildcards.sample}.unsorted.bam 2> {log.other} 

        bedtools bamtofastq -i {params.temp_dir}/{wildcards.sample}.bam -fq {params.temp_dir}/{wildcards.sample}.R1.trimmed.filtered.fastq -fq2 {params.temp_dir}/{wildcards.sample}.R2.trimmed.filtered.fastq 2> {log.other}

        rm -r {params.temp_dir}
        """

rule qc:
    input: 
        expand(rules.qc_filter.output,
               sample=samples),
        rules.raw_per_sample_multiqc.output
